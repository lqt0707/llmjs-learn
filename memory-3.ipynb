{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bba821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { RunnableSequence } from \"@langchain/core/runnables\";\n",
    "import { RunnablePassthrough } from \"@langchain/core/runnables\";\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "import { BufferMemory } from \"langchain/memory\";\n",
    "import { ChatPromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ConversationChain } from \"langchain/chains\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41f1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "const chatModel = new ChatOpenAI({\n",
    "  configuration: {\n",
    "    baseURL: \"https://api.moonshot.cn/v1\",\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "  modelName: \"kimi-k2-0711-preview\",\n",
    "  verbose: true,\n",
    "});\n",
    "const memory =new BufferMemory()\n",
    "\n",
    "const TEMPLATE = `\n",
    "你是一个乐于助人的 ai 助手。尽你所能回答所有问题。\n",
    "\n",
    "这是跟人类沟通的聊天历史:\n",
    "{history}\n",
    "\n",
    "据此回答人类的问题:\n",
    "{input}\n",
    "`;\n",
    "\n",
    "const prompt= ChatPromptTemplate.fromTemplate(TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bc9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "let tempInput = \"\";\n",
    "\n",
    "const chain = RunnableSequence.from([\n",
    "  {\n",
    "    input: new RunnablePassthrough(),\n",
    "    memoryObject: async (input) => {\n",
    "      const history = await memory.loadMemoryVariables({\n",
    "        input,\n",
    "      });\n",
    "      tempInput = input;\n",
    "      return history;\n",
    "    },\n",
    "  },\n",
    "  RunnablePassthrough.assign({\n",
    "    history: (input) => input.memoryObject.history,\n",
    "  }),\n",
    "  prompt,\n",
    "  new RunnablePassthrough({\n",
    "    func: (input) => console.log(input),\n",
    "  }),\n",
    "  chatModel,\n",
    "  new StringOutputParser(),\n",
    "  new RunnablePassthrough({\n",
    "    func: async (output) => {\n",
    "      await memory.saveContext(\n",
    "        {\n",
    "          input: tempInput,\n",
    "        },\n",
    "        {\n",
    "          output,\n",
    "        }\n",
    "      );\n",
    "    },\n",
    "  }),\n",
    "]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d86de",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chain.invoke(\"你好, 我叫小明\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c31fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "await chain.invoke(\"我叫什么？\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec4512",
   "metadata": {},
   "source": [
    "##实现自定义的 chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c41a930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"Hi, 我叫小明\",\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"Hi, 我叫小明\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"你好\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"你好\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import { JSONChatHistory } from \"./JSONChatHistory/index.ts\";\n",
    "import { AIMessage, HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const history = new JSONChatHistory({\n",
    "  dir: \"chat_data\",\n",
    "  sessionId: \"test\",\n",
    "});\n",
    "\n",
    "await history.addMessages([\n",
    "  new HumanMessage(\"Hi, 我叫小明\"),\n",
    "  new AIMessage(\"你好\"),\n",
    "]);\n",
    "\n",
    "const messages = await history.getMessages();\n",
    "console.log(messages);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3118f738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: Hi, 我叫小明\\nAI: 你好\\nHuman: 我叫什么\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.50s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"你刚刚说过，你叫小明呀！\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"你刚刚说过，你叫小明呀！\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 10,\n",
      "                \"promptTokens\": 80,\n",
      "                \"totalTokens\": 90\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 10,\n",
      "      \"promptTokens\": 80,\n",
      "      \"totalTokens\": 90\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const chatModel = new ChatOpenAI({\n",
    "  configuration: {\n",
    "    baseURL: \"https://api.moonshot.cn/v1\",\n",
    "    apiKey: process.env.OPENAI_API_KEY,\n",
    "  },\n",
    "  modelName: \"kimi-k2-0711-preview\",\n",
    "  verbose: true,\n",
    "});\n",
    "const memory = new BufferMemory({ chatHistory: history });\n",
    "const chain = new ConversationChain({\n",
    "  llm: chatModel,\n",
    "  memory,\n",
    "});\n",
    "\n",
    "const res1 = await chain.call({\n",
    "  input: \"我叫什么\",\n",
    "});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28db2378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"Hi, 我叫小明\",\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"Hi, 我叫小明\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"你好\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"你好\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  HumanMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: { content: \"我叫什么\", additional_kwargs: {}, response_metadata: {} },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"我叫什么\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  },\n",
      "  AIMessage {\n",
      "    lc_serializable: true,\n",
      "    lc_kwargs: {\n",
      "      content: \"你刚刚说过，你叫小明呀！\",\n",
      "      additional_kwargs: {},\n",
      "      response_metadata: {}\n",
      "    },\n",
      "    lc_namespace: [ \"langchain_core\", \"messages\" ],\n",
      "    content: \"你刚刚说过，你叫小明呀！\",\n",
      "    name: undefined,\n",
      "    additional_kwargs: {},\n",
      "    response_metadata: {}\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "const messages = await history.getMessages();\n",
    "console.log(messages);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
